{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mlflow --quiet\n!pip install pyngrok --quiet","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:54:02.585762Z","iopub.execute_input":"2023-10-01T16:54:02.586114Z","iopub.status.idle":"2023-10-01T16:54:21.969801Z","shell.execute_reply.started":"2023-10-01T16:54:02.586085Z","shell.execute_reply":"2023-10-01T16:54:21.968471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import mlflow\nimport mlflow.pytorch\nfrom pyngrok import ngrok\nfrom getpass import getpass\nfrom PIL import Image\nimport io\nimport gc\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torchvision import datasets\nfrom torchvision import transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:54:24.875636Z","iopub.execute_input":"2023-10-01T16:54:24.876566Z","iopub.status.idle":"2023-10-01T16:54:28.391452Z","shell.execute_reply.started":"2023-10-01T16:54:24.876525Z","shell.execute_reply":"2023-10-01T16:54:28.390346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_ipython().system_raw(\"mlflow ui --port 5000 &\")\nmlflow.pytorch.autolog()\n\n# Terminate open tunnels if exist\nngrok.kill()\n\n# Setting the authtoken (optional)\n# Get your authtoken from https://dashboard.ngrok.com/auth\nNGROK_AUTH_TOKEN = \"2W9h6RsU2rIUrNR4ZXvwmlUnzt5_MniTnrTgWKSzJVioT3aV\"\nngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\n# Open an HTTPs tunnel on port 5000 for http://localhost:5000\nngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\nprint(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:54:30.928781Z","iopub.execute_input":"2023-10-01T16:54:30.929572Z","iopub.status.idle":"2023-10-01T16:54:38.869575Z","shell.execute_reply.started":"2023-10-01T16:54:30.929531Z","shell.execute_reply":"2023-10-01T16:54:38.868415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_data(dataset,transform):\n    dataset2 = [[0,''] for i in range(len(dataset))]\n\n    for i in range(len(dataset)):\n        image_bytes = dataset[i]['image']['bytes'] # Get bytes\n        image_pil = Image.open(io.BytesIO(image_bytes)) # Convert bytes to PIL Image\n        dataset2[i] = [transform(image_pil),dataset[i]['label']]\n    return dataset2","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:54:38.871081Z","iopub.execute_input":"2023-10-01T16:54:38.871339Z","iopub.status.idle":"2023-10-01T16:54:38.877092Z","shell.execute_reply.started":"2023-10-01T16:54:38.871316Z","shell.execute_reply":"2023-10-01T16:54:38.876366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_loader(dataset,\n                batch_size,\n                random_seed=42,\n                valid_size=0.1,\n                shuffle=True,\n                test=False):\n    \n    print(\"Transforming data\")\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),  # Resize the image to (224, 224)\n        transforms.ToTensor(),          # Convert PIL Image to tensor\n    ])\n\n    if test:\n        data_loader = torch.utils.data.DataLoader(\n            transform_data(dataset,transform), batch_size=batch_size, shuffle=shuffle\n        )\n\n        return data_loader\n\n    # load the dataset\n    train_dataset = transform_data(dataset,transform)\n\n    valid_dataset = train_dataset\n\n    num_train = len(train_dataset)\n    indices = list(range(num_train))\n    split = int(np.floor(valid_size * num_train))\n\n    if shuffle:\n        np.random.seed(42)\n        np.random.shuffle(indices)\n\n    train_idx, valid_idx = indices[split:], indices[:split]\n    train_sampler = SubsetRandomSampler(train_idx)\n    valid_sampler = SubsetRandomSampler(valid_idx)\n\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=batch_size, sampler=train_sampler)\n \n    valid_loader = torch.utils.data.DataLoader(\n        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n\n    return (train_loader, valid_loader)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:54:59.579052Z","iopub.execute_input":"2023-10-01T16:54:59.580086Z","iopub.status.idle":"2023-10-01T16:54:59.587623Z","shell.execute_reply.started":"2023-10-01T16:54:59.580047Z","shell.execute_reply":"2023-10-01T16:54:59.586876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Sequential(\n                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n                        nn.BatchNorm2d(out_channels),\n                        nn.ReLU())\n        self.conv2 = nn.Sequential(\n                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n                        nn.BatchNorm2d(out_channels))\n        self.downsample = downsample\n        self.relu = nn.ReLU()\n        self.out_channels = out_channels\n        \n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.conv2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:55:01.753306Z","iopub.execute_input":"2023-10-01T16:55:01.753689Z","iopub.status.idle":"2023-10-01T16:55:01.761664Z","shell.execute_reply.started":"2023-10-01T16:55:01.753659Z","shell.execute_reply":"2023-10-01T16:55:01.760364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, block, layers, num_classes = 4):\n        super(ResNet, self).__init__()\n        self.inplanes = 64\n        self.conv1 = nn.Sequential(\n                        nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3),\n                        nn.BatchNorm2d(64),\n                        nn.ReLU())\n        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512, num_classes)\n        \n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes:\n            \n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(planes),\n            )\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n    \n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool(x)\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:55:02.674136Z","iopub.execute_input":"2023-10-01T16:55:02.674568Z","iopub.status.idle":"2023-10-01T16:55:02.685386Z","shell.execute_reply.started":"2023-10-01T16:55:02.674530Z","shell.execute_reply":"2023-10-01T16:55:02.684161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(train_loader, model,criterion,optimizer,params,mlflow):\n    \n    print(\"Start training\")\n    \n    for epoch in range(params['num_epochs']):\n        for i, (images, labels) in enumerate(train_loader):  \n            # Move tensors to the configured device\n            images = images.to(device)\n            labels = labels.to(device)\n\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Backward and optimize\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            del images, labels, outputs\n            torch.cuda.empty_cache()\n            gc.collect()\n        \n        # Compute and store train loss\n        mlflow.log_metric('train_loss',loss.item())\n        print ('Epoch [{}/{}], Loss: {:.4f}' \n                       .format(epoch+1, params['num_epochs'], loss.item()))\n    \n    return model,optimizer\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:55:04.564292Z","iopub.execute_input":"2023-10-01T16:55:04.564871Z","iopub.status.idle":"2023-10-01T16:55:04.571117Z","shell.execute_reply.started":"2023-10-01T16:55:04.564842Z","shell.execute_reply":"2023-10-01T16:55:04.570411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validation(valid_loader,model,mlflow):\n    \n    print(\"Start validation\")\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        for images, labels in valid_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            del images, labels, outputs\n\n        mlflow.log_metric('val_acc',100*correct/total)\n        print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total)) ","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:55:07.010430Z","iopub.execute_input":"2023-10-01T16:55:07.010854Z","iopub.status.idle":"2023-10-01T16:55:07.017151Z","shell.execute_reply.started":"2023-10-01T16:55:07.010792Z","shell.execute_reply":"2023-10-01T16:55:07.016066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_model(model,optimizer,name):\n    print(\"Save model \"+ name)\n    checkpoint = {'model': model,\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n    torch.save(checkpoint, name+'.pth')","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:55:13.435367Z","iopub.execute_input":"2023-10-01T16:55:13.435764Z","iopub.status.idle":"2023-10-01T16:55:13.440498Z","shell.execute_reply.started":"2023-10-01T16:55:13.435730Z","shell.execute_reply":"2023-10-01T16:55:13.439767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_experiment(train_loader,valid_loader,model,params,criterion,optimizer,idx):\n    mlflow.log_params(params)\n\n    total_step = len(train_loader)\n    model,optimizer = train(train_loader, model,criterion,optimizer,params,mlflow)\n    \n    validation(valid_loader,model,mlflow)\n\n    mlflow.set_tag(\"Experiment group\",\"Experimento\"+idx)\n    \n    save_model(model,optimizer,'Model'+idx)","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:55:26.160351Z","iopub.execute_input":"2023-10-01T16:55:26.160731Z","iopub.status.idle":"2023-10-01T16:55:26.167190Z","shell.execute_reply.started":"2023-10-01T16:55:26.160701Z","shell.execute_reply":"2023-10-01T16:55:26.166124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlflow.set_tracking_uri(str(ngrok_tunnel.public_url))\nmlflow.set_experiment(\"experiment1\")\n\nprint(\"Loading datasets\")\ndataset_train = load_dataset('Falah/Alzheimer_MRI',split='train')\ndataset_test = load_dataset('Falah/Alzheimer_MRI',split='test')\n\nprint(\"Transforming data\")\ntrain_loader, valid_loader = data_loader(dataset=dataset_train,\n                                         batch_size=64)\n\ntest_loader = data_loader(dataset=dataset_test,\n                              batch_size=64,\n                              test=True)\n\nprint(\"Creating ResNet\")\nmodel = ResNet(ResidualBlock, [3, 4, 6, 3]).to(device)\n\nparams= {\n        'num_classes':4,\n        'num_epochs':[1,2],\n        'batch_size':16,\n        'learning_rate':0.01\n    }\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=params['learning_rate'], weight_decay = 0.001, momentum = 0.9) \n\n\n# Train the model\ntotal_step = len(train_loader)\nnum_runs = 2\nfor i in range(num_runs):\n    with mlflow.start_run():\n        print(\"Start run number \"+str(i))\n        params['num_epochs'] = i\n        mlflow.log_params(params)\n        do_experiment(train_loader,valid_loader,model,params,criterion,optimizer,str(i))","metadata":{"execution":{"iopub.status.busy":"2023-10-01T16:55:32.749699Z","iopub.execute_input":"2023-10-01T16:55:32.750057Z","iopub.status.idle":"2023-10-01T17:04:53.977832Z","shell.execute_reply.started":"2023-10-01T16:55:32.750030Z","shell.execute_reply":"2023-10-01T17:04:53.976223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}